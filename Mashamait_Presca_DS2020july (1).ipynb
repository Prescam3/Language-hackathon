{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S-dCvCUBq9xO"
   },
   "source": [
    "##**Please ensure that these packages before running the notebook preferably on google colab or it will result in errors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lj06CFH0UD0K",
    "outputId": "28a210d0-42f3-4d10-b0c8-382593f809c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-plot\n",
      "  Downloading https://files.pythonhosted.org/packages/7c/47/32520e259340c140a4ad27c1b97050dd3254fdc517b1d59974d47037510e/scikit_plot-0.3.7-py3-none-any.whl\n",
      "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (3.2.2)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (0.22.2.post1)\n",
      "Requirement already satisfied: joblib>=0.10 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (0.17.0)\n",
      "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.18.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.4.7)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib>=1.4.0->scikit-plot) (1.15.0)\n",
      "Installing collected packages: scikit-plot\n",
      "Successfully installed scikit-plot-0.3.7\n",
      "Collecting contractions\n",
      "  Downloading https://files.pythonhosted.org/packages/00/92/a05b76a692ac08d470ae5c23873cf1c9a041532f1ee065e74b374f218306/contractions-0.0.25-py2.py3-none-any.whl\n",
      "Collecting textsearch\n",
      "  Downloading https://files.pythonhosted.org/packages/42/a8/03407021f9555043de5492a2bd7a35c56cc03c2510092b5ec018cae1bbf1/textsearch-0.0.17-py2.py3-none-any.whl\n",
      "Collecting Unidecode\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
      "\u001b[K     |████████████████████████████████| 245kB 5.9MB/s \n",
      "\u001b[?25hCollecting pyahocorasick\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/9f/f0d8e8850e12829eea2e778f1c90e3c53a9a799b7f412082a5d21cd19ae1/pyahocorasick-1.4.0.tar.gz (312kB)\n",
      "\u001b[K     |████████████████████████████████| 317kB 6.6MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n",
      "  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.0-cp36-cp36m-linux_x86_64.whl size=81699 sha256=65955de50d4ded62186ad7320d3cef55f17339eadf21a00a8de77d62420ae83b\n",
      "  Stored in directory: /root/.cache/pip/wheels/0a/90/61/87a55f5b459792fbb2b7ba6b31721b06ff5cf6bde541b40994\n",
      "Successfully built pyahocorasick\n",
      "Installing collected packages: Unidecode, pyahocorasick, textsearch, contractions\n",
      "Successfully installed Unidecode-1.1.1 contractions-0.0.25 pyahocorasick-1.4.0 textsearch-0.0.17\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-plot\n",
    "!pip install contractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ZLmBFyYTKCs"
   },
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z2N63x80TKCt",
    "outputId": "8d116c0f-95da-47f5-ac86-a20929ea2254"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import string\n",
    "from nltk import FreqDist, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "import re\n",
    "import contractions\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier, RidgeClassifierCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import *\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scikitplot.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from wordcloud import WordCloud, STOPWORDS \n",
    "import matplotlib.pyplot as plt \n",
    "from PIL import Image\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 639
    },
    "id": "aJziuVFpTKCu",
    "outputId": "c2191756-8f67-43fd-db22-f80c336b2811"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xho</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nso</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ven</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nso</td>\n",
       "      <td>dinyakišišo tše tša go dirwa gabedi ka ngwaga ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tsn</td>\n",
       "      <td>kgetse nngwe le nngwe e e sa faposiwang mo tsh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ven</td>\n",
       "      <td>mbadelo dze dza laelwa dzi do kwama mahatulele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nso</td>\n",
       "      <td>maloko a dikhuduthamaga a ikarabela mongwe le ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tsn</td>\n",
       "      <td>fa le dirisiwa lebone le tshwanetse go bontsha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>nbl</td>\n",
       "      <td>lapho inarha yangeqadi ingenwe ngokungasimthet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ven</td>\n",
       "      <td>yo dovha hafhu ya khwaṱhisedza uri hu vhe na m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>zul</td>\n",
       "      <td>i-tip-offs anonymous wusizo locingo oluzimele ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ssw</td>\n",
       "      <td>tekulima lokufaka ekhatsi yonkhe imisebenti ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>zul</td>\n",
       "      <td>noma yiliphi ilungu lombutho wezokuvikela elin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>nso</td>\n",
       "      <td>c a fa tumelelo ya go hloma go aga goba go bea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tso</td>\n",
       "      <td>migingiriko ya cbnrm hinkwayo yi katsa ku tumb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>zul</td>\n",
       "      <td>amalungu nabangabasebenzi banelungelo lokwenza...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sot</td>\n",
       "      <td>ka ho mengwa lefapheng la lona diprofeshenale ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>nbl</td>\n",
       "      <td>isitifikhethi somtjhado esingakarhunyezwa namk...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lang_id                                               text\n",
       "0      xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...\n",
       "1      xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...\n",
       "2      eng  the province of kwazulu-natal department of tr...\n",
       "3      nso  o netefatša gore o ba file dilo ka moka tše le...\n",
       "4      ven  khomishini ya ndinganyiso ya mbeu yo ewa maana...\n",
       "5      nso  dinyakišišo tše tša go dirwa gabedi ka ngwaga ...\n",
       "6      tsn  kgetse nngwe le nngwe e e sa faposiwang mo tsh...\n",
       "7      ven  mbadelo dze dza laelwa dzi do kwama mahatulele...\n",
       "8      nso  maloko a dikhuduthamaga a ikarabela mongwe le ...\n",
       "9      tsn  fa le dirisiwa lebone le tshwanetse go bontsha...\n",
       "10     nbl  lapho inarha yangeqadi ingenwe ngokungasimthet...\n",
       "11     ven  yo dovha hafhu ya khwaṱhisedza uri hu vhe na m...\n",
       "12     zul  i-tip-offs anonymous wusizo locingo oluzimele ...\n",
       "13     ssw  tekulima lokufaka ekhatsi yonkhe imisebenti ye...\n",
       "14     zul  noma yiliphi ilungu lombutho wezokuvikela elin...\n",
       "15     nso  c a fa tumelelo ya go hloma go aga goba go bea...\n",
       "16     tso  migingiriko ya cbnrm hinkwayo yi katsa ku tumb...\n",
       "17     zul  amalungu nabangabasebenzi banelungelo lokwenza...\n",
       "18     sot  ka ho mengwa lefapheng la lona diprofeshenale ...\n",
       "19     nbl  isitifikhethi somtjhado esingakarhunyezwa namk..."
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the dataset\n",
    "train = pd.read_csv(\"train_set.csv\")\n",
    "test = pd.read_csv(\"test_set.csv\")\n",
    "#sub_sample = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "train.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 639
    },
    "id": "RMQcmx1CTKCv",
    "outputId": "b2bf3080-066f-45c7-c542-9e9455c37428"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mmasepala, fa maemo a a kgethegileng a letlele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Uzakwaziswa ngokufaneleko nakungafuneka eminye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tshivhumbeo tshi fana na ngano dza vhathu.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Kube inja nelikati betingevakala kutsi titsini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Winste op buitelandse valuta.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Ke feela dilense tše hlakilego, tša pono e tee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>&lt;fn&gt;(762010101403 AM) 1495 Final Gems Birthing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Ntjhafatso ya konteraka ya mosebetsi: Etsa bon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>u-GEMS uhlinzeka ngezinzuzo zemithi yezifo ezi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>So, on occasion, are statistics misused.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Janewari la ngwaga ofe kapa, dikholego tša gag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Ntirho wa mfumo : ku aka swikolo swo ringana n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Kl.(3) e emetswe ke k. 13 ya Molaotheo Tlhabol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Tshabo le ho se sireletsehe hoo ho ile ha baka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Loko u nga ri na ntiyiso wa leswaku xiphiqo xa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>lokuthabatha inxaxheba kwiintshukumo neeprogra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Icandelwana (2) lithathelwe indawo licandelo 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>LaMatsebula Yebo Mtilankhatsa, uva kahle. Wona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Enige persoon wat 'n bepaling van hierdie vero...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Minisi.a' zwi amba Minisi.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                                               text\n",
       "0       1  Mmasepala, fa maemo a a kgethegileng a letlele...\n",
       "1       2  Uzakwaziswa ngokufaneleko nakungafuneka eminye...\n",
       "2       3         Tshivhumbeo tshi fana na ngano dza vhathu.\n",
       "3       4  Kube inja nelikati betingevakala kutsi titsini...\n",
       "4       5                      Winste op buitelandse valuta.\n",
       "5       6  Ke feela dilense tše hlakilego, tša pono e tee...\n",
       "6       7  <fn>(762010101403 AM) 1495 Final Gems Birthing...\n",
       "7       8  Ntjhafatso ya konteraka ya mosebetsi: Etsa bon...\n",
       "8       9  u-GEMS uhlinzeka ngezinzuzo zemithi yezifo ezi...\n",
       "9      10           So, on occasion, are statistics misused.\n",
       "10     11  Janewari la ngwaga ofe kapa, dikholego tša gag...\n",
       "11     12  Ntirho wa mfumo : ku aka swikolo swo ringana n...\n",
       "12     13  Kl.(3) e emetswe ke k. 13 ya Molaotheo Tlhabol...\n",
       "13     14  Tshabo le ho se sireletsehe hoo ho ile ha baka...\n",
       "14     15  Loko u nga ri na ntiyiso wa leswaku xiphiqo xa...\n",
       "15     16  lokuthabatha inxaxheba kwiintshukumo neeprogra...\n",
       "16     17  Icandelwana (2) lithathelwe indawo licandelo 9...\n",
       "17     18  LaMatsebula Yebo Mtilankhatsa, uva kahle. Wona...\n",
       "18     19  Enige persoon wat 'n bepaling van hierdie vero...\n",
       "19     20                         Minisi.a' zwi amba Minisi."
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zo2jqG3PTKCv",
    "outputId": "383da96a-c20e-4ce5-eecb-d5d1e01ab8d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20761, 2), (5682, 2))"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the shapes of the data\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y9VCyyMmTKCv",
    "outputId": "b5173ed5-1ec9-4e8d-d6bb-561623fb10e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20761 entries, 0 to 20760\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   lang_id  20761 non-null  object\n",
      " 1   text     20761 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 324.5+ KB\n"
     ]
    }
   ],
   "source": [
    "#exploring the dataset\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MnTZgU4NTKCw"
   },
   "source": [
    "# Data Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "id": "YOgHvZ6XTKCv",
    "outputId": "ce12c400-7d8d-4d21-a4f8-f51a88830458"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f8b5e025e48>"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train['lang_id'].value_counts().plot(kind= 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "efHBsDpbTKCv"
   },
   "source": [
    "### We have balanced classes each class has 3000 instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qAzzoaeATKCv",
    "outputId": "f889fb78-09a3-4aed-9889-3d8626974445"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lang_id    0\n",
       "text       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "036udcnwTKCv",
    "outputId": "a02415c4-e421-4329-fd48-7ba88d4e5b7d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index    0\n",
       "text     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VR9c948sTKCv"
   },
   "outputs": [],
   "source": [
    "blanks = []  # start with an empty list\n",
    "\n",
    "for i,li,text in train.itertuples():  # iterate over the DataFrame\n",
    "    if type(text)==str:            # avoid NaN values\n",
    "        if text.isspace():         # test 'review' for whitespace\n",
    "            blanks.append(i)     # add matching index numbers to the list\n",
    "\n",
    "train.drop(blanks, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cms-oscFTKCv"
   },
   "outputs": [],
   "source": [
    "blanks = []  # start with an empty list\n",
    "\n",
    "for i,li,text in test.itertuples():  # iterate over the DataFrame\n",
    "    if type(text)==str:            # avoid NaN values\n",
    "        if text.isspace():         # test 'review' for whitespace\n",
    "            blanks.append(i)     # add matching index numbers to the list\n",
    "\n",
    "test.drop(blanks, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vG95w4tBWFrg"
   },
   "outputs": [],
   "source": [
    "def fix_contractions(x):\n",
    "  return contractions.fix(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hD8qsme9XiKd"
   },
   "outputs": [],
   "source": [
    "def token_words(text):\n",
    "  return word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Aj7tVYZQXIa2"
   },
   "outputs": [],
   "source": [
    "def remove_special_characters(text, remove_digits=False):\n",
    "    pattern = r'[^a-zA-z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JJA0U4oFYiYR"
   },
   "outputs": [],
   "source": [
    "def normalize_corpus(corpus, text_lower_case=True,  contraction_expansion=True, special_char_removal=True, remove_digits=True):\n",
    "    \n",
    "    normalized_corpus = []\n",
    "    # normalize each document in the corpus\n",
    "    for doc in corpus:\n",
    "        # strip HTML\n",
    "        # remove accented characters\n",
    "        #if accented_char_removal:\n",
    "        #    doc = remove_accented_chars(doc)\n",
    "        # expand contractions    \n",
    "        if contraction_expansion:\n",
    "            doc = fix_contractions(doc)\n",
    "        # lowercase the text    \n",
    "        if text_lower_case:\n",
    "            doc = doc.lower()\n",
    "        # remove extra newlines\n",
    "        doc = re.sub(r'[\\r|\\n|\\r\\n]+', ' ',doc)\n",
    "        # remove special characters and\\or digits    \n",
    "        if special_char_removal:\n",
    "            # insert spaces between special characters to isolate them    \n",
    "            special_char_pattern = re.compile(r'([{.(-)!}])')\n",
    "            doc = special_char_pattern.sub(\" \\\\1 \", doc)\n",
    "            doc = remove_special_characters(doc, remove_digits=remove_digits)  \n",
    "        # remove extra whitespace\n",
    "        doc = re.sub(' +', ' ', doc)\n",
    "        normalized_corpus.append(doc)\n",
    "        \n",
    "    return normalized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W69pv6kraT85"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UM0A-gIiTKCw"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Clean Data \n",
    "train['text'] = normalize_corpus(train['text'])\n",
    "\n",
    "test['text'] = normalize_corpus(test['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UpCfd9pWTKCv"
   },
   "source": [
    "### Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vyFQvI6RTKCv"
   },
   "outputs": [],
   "source": [
    "# getting y and X metrics \n",
    "X = train['text']\n",
    "y = train['lang_id']\n",
    "# splitting the data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.33, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AOPYblymTKCv"
   },
   "source": [
    "### Training and Tuniing base models on raw data\n",
    "- LinearSVC and RidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KSfkP_XATKCv"
   },
   "outputs": [],
   "source": [
    "# Defining Linearsvc pipeline\n",
    "pipe_lsvc = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', LinearSVC(random_state=0, tol=1e-5)),\n",
    "])\n",
    "\n",
    "# Feed the training data through the pipeline\n",
    "lin_mod = pipe_lsvc.fit(X_train, y_train)  \n",
    "\n",
    "# Form a prediction set\n",
    "lin_pred = lin_mod.predict(X_val)\n",
    "\n",
    "# Print a classification report\n",
    "print(metrics.classification_report(y_val,lin_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fYyOK5vCTKCv"
   },
   "outputs": [],
   "source": [
    "# plotiing confusion metrics\n",
    "plot_confusion_matrix(y_val, lin_pred, normalize=True,figsize=(8,8),cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RT8_fW0QTKCv"
   },
   "outputs": [],
   "source": [
    "# getting our test set ready\n",
    "X_test= test['text']\n",
    "\n",
    "# Making predictions on the dataser and adding a sentiment column to our original test_df\n",
    "test['lang_id'] = lin_mod.predict(X_test)\n",
    "\n",
    "#creating an output csv for submission\n",
    "test[['index','lang_id']].to_csv('testsubmission4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O0JDaaAqTKCv"
   },
   "outputs": [],
   "source": [
    "pipe_lsvc.get_params() # getting the oarameters of Linearsvc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IWqgNzAETKCv"
   },
   "outputs": [],
   "source": [
    "# Hypertuning LinearSCV model\n",
    "lin_param_grid = {'clf__C':[1, 1.01, 1.02, 1.03],\n",
    "                 'tfidf__max_df':(0.9, 0.999),\n",
    "                 'tfidf__min_df':(0, 0.00001, 0.001),\n",
    "                 'tfidf__ngram_range':[(1,2), (1,3), (1,4), (1,5)] \n",
    "                 }\n",
    "cv = StratifiedKFold(n_splits=2,shuffle=True, random_state = 42)\n",
    "grid_search = GridSearchCV(estimator=pipe_lsvc , cv=cv, param_grid=lin_param_grid, n_jobs=-1, scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X, y)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wz9U1rQ_TKCw"
   },
   "outputs": [],
   "source": [
    "# Defining countvectorizer\n",
    "count_vect= CountVectorizer(analyzer = 'char', tokenizer = None,preprocessor = None, stop_words = None, max_features = 180000,min_df = 1,ngram_range = (1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_9rcjSLUTKCw"
   },
   "outputs": [],
   "source": [
    "pipe_Ridge = Pipeline([('vect', count_vect),\n",
    "                     ('ridge', RidgeClassifierCV()),\n",
    "])\n",
    "\n",
    "# Feed the training data through the pipeline\n",
    "ridge_mod = pipe_Ridge.fit(X_train, y_train)  \n",
    "\n",
    "# Form a prediction set\n",
    "ridge_pred = ridge_mod.predict(X_val)\n",
    "\n",
    "# Print a classification report\n",
    "print(metrics.classification_report(y_val,ridge_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yOYGOvoJTKCw"
   },
   "outputs": [],
   "source": [
    "# plotiing confusion metrics\n",
    "plot_confusion_matrix(y_val, ridge_pred, normalize=True,figsize=(8,8),cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bckJiMRFTKCw"
   },
   "outputs": [],
   "source": [
    "# getting our test set ready\n",
    "X_test= test['text']\n",
    "\n",
    "# Making predictions on the dataser and adding a sentiment column to our original test_df\n",
    "test['lang_id'] = ridge_mod.predict(X_test)\n",
    "\n",
    "#creating an output csv for submission\n",
    "test[['index','lang_id']].to_csv('testsubmission10.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6CWQ1h7sTKCw"
   },
   "outputs": [],
   "source": [
    "pipe_naive =Pipeline([('clf',  TfidfVectorizer()),\n",
    "                      ('svc', MultinomialNB()),\n",
    "                     ])\n",
    "# Feed the training data through the pipeline\n",
    "naive_mod = pipe_naive.fit(X_train, y_train)  \n",
    "\n",
    "# Form a prediction set\n",
    "naive_pred = naive_mod.predict(X_val)\n",
    "\n",
    "# Print a classification report\n",
    "print(metrics.classification_report(y_val,naive_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vahSFEvYc8kY"
   },
   "outputs": [],
   "source": [
    "naive_mod.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D9sVM196daan"
   },
   "outputs": [],
   "source": [
    "params={\n",
    "    'clf__ngram_range': [(1, 1),(1,2),(1,3),(1,4)],\n",
    "    'svc__alpha':[0.001,0.01,0.1,1]\n",
    "}\n",
    "Kfold = StratifiedKFold(n_splits=5,shuffle=True,random_state=42)\n",
    "grid = GridSearchCV(pipe_naive,param_grid=params,n_jobs=-1,cv=Kfold,verbose=3)\n",
    "\n",
    "grid.fit(X_train,y_train)\n",
    "model = grid.best_estimator_\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid.best_score_, grid.best_params_))\n",
    "means = grid.cv_results_['mean_test_score']\n",
    "stds = grid.cv_results_['std_test_score']\n",
    "params = grid.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iOE-8quCcS6X"
   },
   "outputs": [],
   "source": [
    "# getting our test set ready\n",
    "X_test= test['text']\n",
    "\n",
    "# Making predictions on the dataser and adding a sentiment column to our original test_df\n",
    "test['lang_id'] = grid.best_estimator_.predict(X_test)\n",
    "\n",
    "#creating an output csv for submission\n",
    "test[['index','lang_id']].to_csv('testsubmission12.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z96Yy4DqTKCw"
   },
   "outputs": [],
   "source": [
    "# plotiing confusion metrics\n",
    "plot_confusion_matrix(y_val, naive_pred, normalize=True,figsize=(8,8),cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H5XreX7u45BV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hMa_Mhf2TKCw"
   },
   "outputs": [],
   "source": [
    "# Training models on clean data\n",
    "pipe_lsvc = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', LinearSVC(random_state=0, tol=1e-5)),\n",
    "])\n",
    "\n",
    "# Feed the training data through the pipeline\n",
    "lin_mod = pipe_lsvc.fit(X_train, y_train)  \n",
    "\n",
    "# Form a prediction set\n",
    "lin_pred = lin_mod.predict(X_val)\n",
    "\n",
    "# Print a classification report\n",
    "print(metrics.classification_report(y_val,lin_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EIc5R2VdTKCw"
   },
   "outputs": [],
   "source": [
    "# getting our test set ready\n",
    "X_test= test['text']\n",
    "\n",
    "# Making predictions on the dataser and adding a sentiment column to our original test_df\n",
    "test['lang_id'] = lin_mod.predict(X_test)\n",
    "\n",
    "#creating an output csv for submission\n",
    "test[['index','lang_id']].to_csv('testsubmission8.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VuQbbTiVqGhv"
   },
   "outputs": [],
   "source": [
    "# Defining countvectorizer\n",
    "count_vect= CountVectorizer(analyzer = 'char', tokenizer = None,preprocessor = None, stop_words = None, max_features = 180000,min_df = 1,ngram_range = (1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rQDETjCjTKCw"
   },
   "outputs": [],
   "source": [
    "pipe_Ridge = Pipeline([('vect', count_vect),\n",
    "                     ('clf', RidgeClassifierCV()),\n",
    "])\n",
    "\n",
    "# Feed the training data through the pipeline\n",
    "ridge_mod = pipe_Ridge.fit(X_train, y_train)  \n",
    "\n",
    "# Form a prediction set\n",
    "ridge_pred = ridge_mod.predict(X_val)\n",
    "\n",
    "# Print a classification report\n",
    "print(metrics.classification_report(y_val,ridge_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7mNQzElJTKCw"
   },
   "outputs": [],
   "source": [
    "# getting our test set ready\n",
    "X_test= test['text']\n",
    "\n",
    "# Making predictions on the dataser and adding a sentiment column to our original test_df\n",
    "test['lang_id'] = ridge_mod.predict(X_test)\n",
    "\n",
    "#creating an output csv for submission\n",
    "test[['index','lang_id']].to_csv('testsubmission9.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QSDuxalnTKCw"
   },
   "outputs": [],
   "source": [
    "def train_knn(x, y, k):\n",
    "    '''Returns the trained k nearest neighbors classifier\n",
    "    \n",
    "    train_knn(x, y, k) -> sklearn.neighbors.KNeighborsClassifier\n",
    "    '''\n",
    "    pipe_knn = pipe_naive =Pipeline([('clf',  TfidfVectorizer()),\n",
    "                      ('knn', KNeighborsClassifier(k)),\n",
    "                     ])\n",
    "    pipe_knn.fit(X_train, y_train)\n",
    "    return pipe_knn\n",
    " \n",
    "def test_knn(pipe_knn, X, Y):\n",
    "    '''Tests a given classifier with a testset and return result\n",
    "    \n",
    "    text_knn(clf, X, Y) -> float\n",
    "    '''\n",
    "    predictions = pipe_knn.predict(X_val)\n",
    "    ratio_correct = accuracy_score(y_val, predictions)\n",
    "    return ratio_correct\n",
    " \n",
    "print('''k\\tPercentage of correctly predicted language\n",
    "__________________________________________________''')\n",
    "for i in range(1, 16):\n",
    "    clf = train_knn(X_train, y_train, i)\n",
    "    ratio_correct = test_knn(clf, X_val, y_val)\n",
    "    print(str(i) + '\\t' + str(round(ratio_correct * 100, 3)) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V-S9YtsdnYfN"
   },
   "outputs": [],
   "source": [
    "knn_mod = train_knn(X_train,y_train,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vUd22zVYn11g"
   },
   "outputs": [],
   "source": [
    "kn_accuracy = test_knn(knn_mod,X_val,y_val)\n",
    "print(kn_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xsksLh3Mopl8"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aGbOQ6M3ofXT"
   },
   "outputs": [],
   "source": [
    "# getting our test set ready\n",
    "X_test= test['text']\n",
    "\n",
    "# Making predictions on the dataser and adding a sentiment column to our original test_df\n",
    "test['lang_id'] = knn_mod.predict(X_test)\n",
    "\n",
    "#creating an output csv for submission\n",
    "test[['index','lang_id']].to_csv('testsubmission13.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dq0Vp96ZuW7x"
   },
   "source": [
    "Naive Bayes obtained higher score as to compared to other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KE0y7xms3ZZt"
   },
   "outputs": [],
   "source": [
    "# Defining Linearsvc pipeline\n",
    "pipe_log = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('clf', LogisticRegression(C=0.90,max_iter=1000,penalty='l2' )),\n",
    "])\n",
    "\n",
    "# Feed the training data through the pipeline\n",
    "log_mod = pipe_log.fit(X_train, y_train)  \n",
    "\n",
    "# Form a prediction set\n",
    "log_pred = log_mod.predict(X_val)\n",
    "\n",
    "# Print a classification report\n",
    "print(metrics.classification_report(y_val,log_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KgwWP0wE49B4"
   },
   "outputs": [],
   "source": [
    "# plotiing confusion metrics\n",
    "plot_confusion_matrix(y_val, log_pred, normalize=True,figsize=(8,8),cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uJGsu3sR5IQY"
   },
   "outputs": [],
   "source": [
    "# getting our test set ready\n",
    "X_test= test['text']\n",
    "\n",
    "# Making predictions on the dataser and adding a sentiment column to our original test_df\n",
    "test['lang_id'] = log_mod.predict(X_test)\n",
    "\n",
    "#creating an output csv for submission\n",
    "test[['index','lang_id']].to_csv('testsubmission13.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Mashamait_Presca_DS2020july.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
